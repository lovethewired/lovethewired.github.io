{"pageProps":{"postData":{"slug":["blog","2023","test-your-tests"],"contentRaw":"\n> This is a writeup of the talks given at [TrustX](https://www.secureum.xyz/trustx/) and [Solidity Summit](https://soliditylang.org/summit/) at [Devconnect Istanbul 2023](https://devconnect.org/).\n\nIn the rapidly evolving landscape of software development, the importance of rigorous testing cannot be overstated, especially when dealing with system-critical applications like blockchains. The reliability of tests are fundamental to ensuring the integrity and security of the applications they support. But, how do we evaluate the quality and efficacy of our tests?\n\n## Key Insights:\n\n1. **Treat Tests with the Same Rigor as Production Code**: Treat your unit, fuzz, and integration tests with the same seriousness as your main application code. Given that tests can also harbor bugs, their detailed assessment is crucial. A flawed test may not just yield incorrect outcomes but could also create a deceptive sense of security.\n\n2. **Critically Examine the Assumptions, Preconditions, and Conclusions in Tests**:\n\n   - Re-evaluate your preconditions. Are they backed by concrete examples?\n   - Review your test conclusions. Are there hidden assumptions that might skew the outcomes?\n\n3. **Incorporate 'Meta-Tests'**:\n\n   - Design tests to evaluate your primary tests.\n   - Examine specific edge cases with dedicated unit tests.\n   - Introduce intentional bugs to see if your tests spot them.\n   - Use mutation testing to check the resilience of your tests.\n\n4. **Understand the Limitations of Testing Tools**: While testing tools enhance our testing abilities, they have their limitations. These tools can contain inherent biases, idiosyncrasies, or bugs. Not fully grasping their capabilities or misapplying them might distort test results.\n\n## The Role of Robust Testing\n\nTests act as the protective layer for code functionality. A well-crafted designed test solidifies the anticipated code behavior, safeguarding it against unexpected issues that might arise from future modifications.\nEven though various testing methods and static analysis can vouch for your code's stability, no test is infallible. Constant attention and improvement in testing methods are essential for ensuring software robustness.\n\n### Motivation Behind the Topic\n\nThis topic's inspiration stems from my own experiences and reflections on past shortcomings. Each identified vulnerability prompted a re-evaluation—-how could both the development and testing phases be enhanced to avert similar challenges in the future?\n\n### Exemplary Case: The WAD Conversion\n\nTo shed light on the concepts discussed, consider a simple exercise of writing a fuzz test for WAD unit conversions.\n\n```js\nuint256 constant WAD = 1e18;\n\nfunction fromWAD(uint256 a) pure returns (uint256 c) {\n    c = a / WAD;\n}\n\nfunction toWAD(uint256 a) pure returns (uint256 c) {\n    c = a * WAD;\n}\n\ncontract TestFromWAD_DONT is Test {\n    function test_toWAD_fromWAD(uint256 a) external {\n        if (a >= type(uint256).max / WAD) vm.expectRevert();\n\n        assertEq(fromWAD(toWAD(a)), a);\n    }\n}\n```\n\nWhile the above test passed numerous fuzzing iterations, a closer examination reveals an oversight in the boundary check. Specifically, the conversion should not revert for `a = type(uint256).max / WAD`. From the fuzzer's perspective, this value might appear as any other in the space of all possible `uint256` inputs. This inaccuracy exemplifies how an unclear precondition can not only obfuscate the true functionality but, in more severe scenarios, also mask vulnerabilities.\n\nAn improved version of the test could be structured as:\n\n```js\ncontract TestFromWAD_DO is Test {\n    /// Testing for values where `toWAD(a)` shouldn't revert.\n    function test_toWAD_fromWAD(uint256 a) public {\n        a = bound(a, 0, type(uint256).max / WAD);\n\n        assertEq(fromWAD(toWAD(a)), a);\n    }\n\n    /// Testing for values where `toWAD(a)` should revert.\n    function test_toWAD_fromWAD_revert_Panic(uint256 a) public {\n        a = bound(a, type(uint256).max / WAD + 1, type(uint256).max);\n\n        vm.expectRevert(abi.encodeWithSignature(\"Panic(uint256)\", (0x11)));\n\n        assertEq(fromWAD(toWAD(a)), a);\n    }\n}\n```\n\n$$uint256 \\text{ domain}$$\n\n$$\n\\overset{\\raisebox{2pt}{\\color{green} passing}}{\n    ├\\underset{0}{─}────────────\\underset{\\hskip -1em \\frac {MAX} {WAD}}{─}┤\n}\n\\overset{\\raisebox{2pt} {\\color{red}reverting}}{\n    ├────\\underset{\\hskip -3.5em \\frac {MAX} {WAD} + 1}───────\\underset{\\hskip -0.4 em MAX }{───}┤\n}\n$$\n\nBy dividing tests based on expected results (success or failure), our testing approach becomes clearer and ensures both situations are sufficiently tested. Using Foundry's `bound` function aids in testing near boundary conditions. Also, testing for a specific error (`Panic(0x11)`) can identify unintentional coding errors.\n\nAs a further improvement, one could segregate the calls `fromWAD(toWAD(a))` to pinpoint exactly where an error might occur. This would require the calls to be made externally.\n\nIt's worth noting, however, that the tests alone don't offer a clear picture of the actual behavior of the `toWAD` and `fromWAD` functions. Multiple functions can satisfy the constraints set by the tests, as illustrated below:\n\n```js\nfunction fromWAD(uint256 a) pure returns (uint256 c) {\n    c = a + 1234;\n}\n\nfunction toWAD(uint256 a) pure returns (uint256 c) {\n    if (a > type(uint256).max / WAD) revert();\n    c = a - 1234;\n}\n```\n\n### Exemplary Case: Mul WAD\n\nWe just saw the case where our test had a wrong precondition compared to our implementation. What if, however, our test reflected an incorrect precondition contained in the implementation itself?\n\n```js\ncontract TestMulWAD_DONT is Test {\n    function mulWAD(uint256 a, uint256 b) public pure returns (uint256 c) {\n        unchecked {\n            if (b == 0 || a > type(uint256).max / b) revert Overflow();\n\n            c = a * b / WAD;\n        }\n    }\n\n    function test_mulWAD(uint256 a, uint256 b) public {\n        if (b == 0 || a > type(uint256).max / b) vm.expectRevert();\n\n        uint256 c = mulWAD(a, b);\n\n        assertEq(c, a * b / WAD);\n    }\n}\n```\n\nThis example implementation of `mulWAD` is using `unchecked` arithmetic for optimization purposes. In doing so, we have manually included a flawed check that will revert the execution when an overflow occurs. This flawed check is now mirrored in the test and cannot be detected by a fuzzer. How would we have been able to detect the error in this case?\n\nIn the case that we have a reference implementation at hand, we can use differential fuzz testing.\n\n```js\n    function mulWADNative(uint256 a, uint256 b) public pure returns (uint256 c) {\n        c = a * b / WAD;\n    }\n\n    function test_mulWAD_differential(uint256 a, uint256 b) public {\n        assertEqCall(\n            address(this),\n            abi.encodeCall(this.mulWAD, (a, b)),\n            abi.encodeCall(this.mulWADNative, (a, b))\n        );\n    }\n```\n\nUsing the `ffi` cheat code we can also test against non Solidity implementations.\n\n**Takeaway:**\n\n- Don't blindly copy preconditions (or code) from your implementations when testing\n- Re-implement code logic and use **differential testing** when possible\n\n# Ensuring The Efficacy of Testing: The Case of Primitive Finance Hyper Swap\n\nIn our pursuit of understanding the security of applications, we often focus on verifying the correctness of properties we know or expect to hold. However, sometimes, the more revealing approach is the opposite—trying to invalidate or disprove properties we suspect might not hold. This is what we term as the \"offensive\" side of testing.\n\nDuring the audit of Primitive Hyper in January, a few notable characteristics of the system were observed:\n\n- It's a CFMM (Constant Function Market Maker) protocol incorporating time-dependent curves, potentially enabling options trading.\n- The system manages internal accounting for pool balances along with a batch swapping functionality.\n- It heavily employs assembly language and intricate function approximations such as solstat, pdf, and erfc. Additionally, it has inconsistent rounding methods.\n\n## Initial Testing Strategy\n\nIn the early stages of the audit, a natural inclination was to utilize fuzz testing. The hypothesis was simple: Can one exploit inaccuracies in the pool's state (parameters, reserves, etc.) to achieve favorable swaps? The goal was to determine if repeated swaps could lead to value extraction.\n\nBelow is an excerpt from an initial test attempt:\n\n```js\n    function test_swap(\n        bool sellAsset,\n        uint128 input,\n        uint128 tempOutput,\n        uint256 liquidity,\n        uint256 volatility,\n        uint256 duration,\n        uint128 stkPrice,\n        uint128 price\n    ) public {\n        // Alice create's an honest pool with liquidity.\n        createPoolAndAllocateLiquidity(alice, 100, 10, 2e18, 1e18, 1_000_000 * 1e18);\n\n        // Bob create's a malicious pool with liquidity.\n        createPoolAndAllocateLiquidity(bob, volatility, duration, stkPrice, price, liquidity);\n\n        // Bob tries to extract tokens by swapping back and forth.\n        uint128 targetValue = 1e18;\n\n        // Swap input X -> tempOutput Y -> output X.\n        bool success = swapBackAndForth(sellAsset, input, tempOutput, input + targetValue);\n        if (!success) return;\n\n        // Bob withdraws all of his assets.\n        withdrawAllAssets(bob);\n\n        int256 assetGain = int256(asset.balanceOf(bob)) - int256(INITIAL_BALANCE);\n        int256 quoteGain = int256(quote.balanceOf(bob)) - int256(INITIAL_BALANCE);\n\n        // Bob should gain tokens.\n        if (assetGain < 0 || quoteGain < 0) return;\n\n        // Log the balance gain.\n        console.log(\"Asset gain\", vm.toString(assetGain));\n        console.log(\"Quote gain\", vm.toString(quoteGain));\n\n        // Report the test case.\n        fail();\n    }\n```\n\n```\nTraces:\n  [128911] self::test_swap(false, 0, 0, 0, 0, 0, 0, 0)\n    ├─ [0] VM::startPrank(alice: [0x00000000000000000000000000000000000A11cE])\n    │   └─ ← ()\n    ├─ [113457] HYPER::aa012c0c(5991a2df15a8f6a256d3ec51e99254cd3fb576a9f62849f9a0b5bf2913b396098f7c7019b51a820a)\n    │   ├─ emit CreatePair(pairId: 1, asset: ASSET: [0x5991A2dF15A8F6A256D3Ec51E99254Cd3fb576A9], quote: QUOTE: [0xF62849F9A0B5Bf2913b396098F7c7019b51A820a], decimalsAsset: 18, decimalsQuote: 18)\n    │   └─ ← ()\n    └─ ← \"UNDEFINED\"\n```\n\n```\nTraces:\n  [306133] self::test_swap(false, 0, 0, 170141183460469231731687303715884105728 [1.701e38], 0, 0, 0, 0)\n    ├─ [0] VM::startPrank(alice: [0x00000000000000000000000000000000000A11cE])\n    │   └─ ← ()\n    ├─ [113457] HYPER::aa012c0c(5991a2df15a8f6a256d3ec51e99254cd3fb576a9f62849f9a0b5bf2913b396098f7c7019b51a820a)\n    │   ├─ emit CreatePair(pairId: 1, asset: ASSET: [0x5991A2dF15A8F6A256D3Ec51E99254Cd3fb576A9], quote: QUOTE: [0xF62849F9A0B5Bf2913b396098F7c7019b51A820a], decimalsAsset: 18, decimalsQuote: 18)\n    ...\n    ├─ [5912] HYPER::allocate(1103806595073 [1.103e12], 170141183460469231731687303715884105728 [1.701e38])\n    │   └─ ← \"EvmError: Revert\"\n    └─ ← \"EvmError: Revert\"\n```\n\nHowever, multiple test runs encountered frequent reverts, indicating the inability to achieve the envisioned swaps. It would be easy, albeit premature, to interpret this as a sign of robustness against the hypothesized exploit.\n\n```js\n    function test_swap(\n        bool sellAsset,\n        // ...\n    ) public {\n        // Properly bound pool parameters.\n        // Prevent lnWad's \"UNDEFINED\" when `price * 1e18 / stkPrice == 0`.\n        stkPrice = uint128(bound((stkPrice), 1, type(uint128).max));\n        price = uint128(\n            bound(\n                uint256(price),\n                (Price.computePriceWithTick(Price.computeTickWithPrice(stkPrice) + 1) + 1e18 - 1) / 1e18,\n                type(uint128).max\n            )\n        );\n        volatility = bound(volatility, 100, 25_000);\n        duration = bound(duration, 1, 500);\n\n        // Alice create's a pool with liquidity.\n        // ...\n    }\n```\n\n```\nRunning 1 test for test/foundry/TestSwapPoc.t.sol:TestHyperSwapPoc\n[PASS] test_swap(bool,uint128,uint128,uint256,uint256,uint256,uint128,uint128) (runs: 10000, μ: 723780, ~: 794869)\nTest result: ok. 1 passed; 0 failed; 0 skipped; finished in 10.23s\n```\n\nOk, great. After addressing all reverts and properly bounding the parameters, all runs are completing. Bob has still not made any profitable trades however.\n\n## Refining the Testing Strategy\n\nInstead of stopping, the testing process continued, and the focus shifted. By letting the fuzzer operate over an extended duration and periodically revisiting the codebase, more insights were gained.\n\nOne significant discovery was the reliance on Hyper's batch instructions for the swapping process. Coverage indicated that I was able to create pools and allocate liquidity, but not execute the profitable swap.\n\n```js\n    function swapBackAndForth(bool sellAsset, uint128 input, uint128 output1, uint128 output2)\n        internal\n        returns (bool success)\n    {\n        // Encode batch instructions.\n        bytes[] memory instructions = new bytes[](2);\n\n        instructions[0] = ProcessingLib.encodeSwap(0, poolId, 0, input, 0, output1, sellAsset ? 0 : 1);\n        instructions[1] = ProcessingLib.encodeSwap(0, poolId, 0, output1, 0, output2, sellAsset ? 1 : 0);\n\n        bytes memory data = ProcessingLib.encodeJumpInstruction(instructions);\n\n        (success,) = address(hyper).call(data);\n    }\n```\n\nDue to the settlement logic, all net balances are deducted at the end of a batched instruction. If a successful attack means only receiving tokens from the protocol why would an attacker be required to give token approvals to the protocol? However, due to rounding inconsistencies, attempting to extract Quote tokens often required the transferring at least one Asset token.\n\nMoreover, it was observed that the exploit was only feasible if the attacker did not receive the special pool controller fee but the standard swap fee. This highlighted the significance of questioning assumptions and testing varying conditions.\n\n## Conclusions and Takeaways\n\nThe Primitive Hyper Swap case offers several insights that can be applied to:\n\n4. **Establish Precise Variable Bounds**: Address potential reverts by ensuring that all variables are bounded correctly.\n5. **Augment Coverage Insight**: Introduce sanity checks to assess the feasibility of the test hypothesis, even considering the removal of protocol invariant checks.\n6. **Challenge Every Assumption**: The audit revealed how certain assumptions, like the fixed priority fee required for the exploit, or the prerequisite of token approvals, can skew testing results.\n\nIn essence, offensive testing requires a dynamic and persistent approach. It's not just about confirming the robustness of a system but actively seeking potential cracks. Only by repeatedly challenging our understanding and assumptions can we hope to uncover hidden vulnerabilities.\n","title":"Test Your Tests!","date":"Oct 20, 2023","excerpt":"Writeup of the talks given at TrustX & Solidity Summit at Devconnect in Istanbul.","suptitle":"The Dos and Don'ts of testing","unpublished":true}},"__N_SSG":true}