{"pageProps":{"postData":{"slug":["unpublished","shared-sequencing"],"contentRaw":"\n- [What is shared sequencing?](#what-is-shared-sequencing)\n  - [What is a rollup?](#what-is-a-rollup)\n  - [What is the sequencer's role?](#what-is-the-sequencers-role)\n  - [Why should we care about decentralizing the sequencer?](#why-should-we-care-about-decentralizing-the-sequencer)\n    - [Data Availability and submission cost amortization](#data-availability-and-submission-cost-amortization)\n    - [Trust + infra outsourcing](#trust--infra-outsourcing)\n    - [Cross-chain atomicity](#cross-chain-atomicity)\n  - [Why is the sequencer so important?](#why-is-the-sequencer-so-important)\n    - [Transaction censoring or delay](#transaction-censoring-or-delay)\n    - [MEV extraction (reordering, inserting)](#mev-extraction-reordering-inserting)\n- [Overview of a shared sequencer architecture](#overview-of-a-shared-sequencer-architecture)\n  - [Architecture overview](#architecture-overview)\n  - [Rollup agnostic](#rollup-agnostic)\n  - [Consensus algorithm](#consensus-algorithm)\n  - [Transaction sequence proof](#transaction-sequence-proof)\n- [Technical Difficulties](#technical-difficulties)\n  - [Builder market](#builder-market)\n  - [Multi-rollup](#multi-rollup)\n  - [Consensus](#consensus)\n  - [Data Availability](#data-availability)\n- [Current state of shared sequencing](#current-state-of-shared-sequencing)\n  - [Overview of different platforms](#overview-of-different-platforms)\n  - [Rollup alignment](#rollup-alignment)\n- [Research questions and outlooks](#research-questions-and-outlooks)\n- [Conclusion](#conclusion)\n\n# What is shared sequencing?\n\n## What is a rollup?\n\nA rollup chain—a layer 2 blockchain—is a blockchain that builds on top of another host blockchain—the layer 1 blockchain. It can be characterized in a few key points:\n\n1. Builds on top of L1\n2. Inherits L1 security: Objective finality (fraud proofs or validity proofs)\n3. Liveness guarantees from L1: L1 chain unlikely to go offline\n4. Data availability guaranteed through L1: Transactions are posted as calldata or blobs\n5. Cheaper due to transaction compression, off-chain execution and small state commits\n\nThe L2 chain inherits the L1 chain's finality guarantees. Once a fraud proof window has passed or a validity proof has been included into a finalized L1 block, it is automatically finalized as seen by the L2. A double spending attack would require a L1 chain block reorganization.\n\nThe L2 chain also benefits from the host chain's decentralized validator set and economic security in terms of liveness. The L1 chain is unlikely to go offline and censor transactions. In principle, the rollup should be able to continue advancing its state and produce blocks as long as the L1 chain is online.\n\nThe layer 2 blockchain will likely run a layer 1 node in parallel. Since all the relevant layer 2 transaction data is available when syncing the layer 1 node—either through L1 calldata or EIP-4844 data blobs—the state of the layer 2 block chain can be recomputed entirely by only relying on data from the host blockchain.\n\nRollups benefit from cheaper transaction costs. This is because layer 2 transaction data can be compressed and decompressed off-chain. Also, costly updates to the state database and execution does not happen on the more expensive layer 1 chain. Only every N block/state commits are required to be stored in the host chain's rollup contract.\n\nA big challenge that most rollups face today is meeting the demand for faster finality than L1 for improved user experience. This forces the rollup to use a centralized & trusted sequencer.\n\n## What is the sequencer's role?\n\nWhen a user sends a layer 2 transaction, it is first picked up by the sequencer. The sequencer's job is to commit to a transaction ordering such that the new rollup state can be determined reliably. Once the ordering is set, all other node operators can compute the rollup's new state by applying the deterministic state transition function iteratively producing layer 2 blocks.\n\n![Arbitrum's transaction lifecycle](arbitrum-nitro-whitepaper-transaction.png)\n\n1.  Sequencer receives multiple user transactions\n2.  Sequencer orders these\n3.  Sequencer sends out an ordering promise (feed)\n4.  Batched and compressed transactions are committed to L1 chain\n5.  The L2 transactions are executed off-chain\n6.  The new L2 blocks are confirmed to the L1 chain\n\nThe new state can be computed by running the Nitro Geth fork which also fetches the transaction data from the layer 1 blockchain. The transaction data itself does not necessarily need to be committed to persistent state. It is often only included as transaction calldata to the sequencers ordering commitment such that layer 1 operators are able to fetch and process the transactions. An alternative that has been made possible recently through EIP-4844 is to use data blobs for the transaction data availability.\n\nWhile fraud proving an invalid block is less permissioned, the sequencer is arguably the most centralized component of today's layer 2 rollups.\n\nThe reason that the shared sequencer often is a centralized component today is that it is quite an engineering feat to implement. All other rollup components work deterministic and are clear to compute, whereas decentralizing the sequencer requires an additional consensus algorithm or auctioning mechanism. Along with this come a plethora of fairness, economic security and decentralized coordination questions and concerns. Similar to the advantages of being able to produce the block on a layer 1 blockchain, being able to determine the transaction ordering comes with the ability of extracting user value and transaction censorship.\n\n## Why should we care about decentralizing the sequencer?\n\nBuilding a shared sequencer that is fast, incorruptible and decentralized might seem like a **big engineering undertaking** that probably will come with a slightly **worse user experience**, **additional security risks** and a **loss in autonomy and fees for rollups**. _Why would we even want and care for decentralizing the sequencer?_\n\nAs with many blockchain components, a **central point of failure** is not desirable. The goal is to build censorship resistant and resilient infrastructure that cannot be corrupted in the moment when it counts. Having a centralized component inevitably means that a party with enough influence might be able to corrupt the component if the desire is high enough. This can in the form of a government decree that aims to censor certain users and protocols or by any actor with a shared interest. **Censorship and inclusion delays** can even come from the rollup's sequencer themselves. Further, an accidental server crash or data breach can occur leading to protocol **liveness** issues. Or worse, a sequencer might not fulfill its promise to include pre-committed transactions opening up the possibility of **double spend attacks**.\n\nCurrently, most centralized sequencers handle incoming user transactions via a private transaction mem-pool on a first come first serve basis. Having complete control over the sequencer also means that there is a monopoly on inclusion and ordering pricing. In principle, the sequencer stands to benefit from performing MEV (front and back-running, delaying or including its own transactions) or from selling the block building rights.\n\nIn summary, the following reasons highlight why we would want to move away from a centralized sequencer:\n\n- Censorship resistance\n- Robustness: Liveness\n- Trust requirements\n- Block building rights for all\n\nIf a sequencer is decentralized, there is no need for it to only server one rollup. A decentralized sequencing protocol might as well act as a shared sequencing abstraction layer that multiple rollups can plug into. This opens up the door to the possibility of atomic composability between rollups. Outsourcing the sequencer role for rollups to a shared sequencer service can come with the added benefits of:\n\n- Decentralized sequencing\n- Outsourced development cost\n- Higher code security guarantees\n- Atomic composability\n- Batch posting cost amortization\n\nFurther, some shared sequencer services want to provide even more value, such as:\n\n- Pre-execution privacy (encrypted mem-pool)\n- Subsidized transactions & MEV revenue share\n- Reduced costs: Integration with Data availability layer\n- Guaranteed pre-commits\n- Restaking ability\n- Top of block auctions\n\nIt is unclear whether most rollups will be interested in sharing a sequencer. As block building rights can be auctioned off at high prices and can lead to bad user experience, most bigger rollup chains will likely employ their own solutions and either capture and redistribute or use a fair ordering mechanism. Decentralizing the sequencer is currently part of Arbitrum's and Optimism's roadmap. Smaller blockchains with less engineering manpower will be happy to plug in a modular component that offers a decentralized sequencing solution with some added benefit:\n\n- Decentralized sequencing\n- Outsourcing development\n- Higher security guarantees\n- Data availability and liveness amortization\n\n### Data Availability and submission cost amortization\n\n### Trust + infra outsourcing\n\n### Cross-chain atomicity\n\n## Why is the sequencer so important?\n\n### Transaction censoring or delay\n\n### MEV extraction (reordering, inserting)\n\n# Overview of a shared sequencer architecture\n\n## Architecture overview\n\n## Rollup agnostic\n\n## Consensus algorithm\n\n## Transaction sequence proof\n\n# Technical Difficulties\n\n## Builder market\n\n## Multi-rollup\n\n## Consensus\n\n## Data Availability\n\n# Current state of shared sequencing\n\n## Overview of different platforms\n\n## Rollup alignment\n\n# Research questions and outlooks\n\n# Conclusion\n","title":"Shared Sequencing","date":"Apr 24, 2024"}},"__N_SSG":true}